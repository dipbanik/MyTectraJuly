{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Preprocessing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQMO6tFvg_wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "#used for data preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjF9WPR5ph-u",
        "colab_type": "text"
      },
      "source": [
        "##Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbqbqdYGhp7q",
        "colab_type": "code",
        "outputId": "de6a9e61-0e11-4b11-845b-8b8f2ded6e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis=0)\n",
        "# use mean median or mode according to the need.\n",
        "#axis = 0 means that we take the mean of the column.\n",
        "#axis = 1 means that we are going to take the mean of the row."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsNZhA2yjHhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get data\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/dipbanik/MyTectraJuly/master/Data_Preprocessing_and_Bias_Variance/Data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ_ZhITVUHXS",
        "colab_type": "code",
        "outputId": "253f157a-ab55-420c-9ff8-5a255c480c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Age</th>\n",
              "      <th>Salary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>France</td>\n",
              "      <td>44.0</td>\n",
              "      <td>72000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Spain</td>\n",
              "      <td>27.0</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Germany</td>\n",
              "      <td>30.0</td>\n",
              "      <td>54000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Spain</td>\n",
              "      <td>38.0</td>\n",
              "      <td>61000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Germany</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>France</td>\n",
              "      <td>35.0</td>\n",
              "      <td>58000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Spain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>France</td>\n",
              "      <td>48.0</td>\n",
              "      <td>79000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Germany</td>\n",
              "      <td>50.0</td>\n",
              "      <td>83000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>France</td>\n",
              "      <td>37.0</td>\n",
              "      <td>67000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Country   Age   Salary Purchased\n",
              "0   France  44.0  72000.0        No\n",
              "1    Spain  27.0  48000.0       Yes\n",
              "2  Germany  30.0  54000.0        No\n",
              "3    Spain  38.0  61000.0        No\n",
              "4  Germany  40.0      NaN       Yes\n",
              "5   France  35.0  58000.0       Yes\n",
              "6    Spain   NaN  52000.0        No\n",
              "7   France  48.0  79000.0       Yes\n",
              "8  Germany  50.0  83000.0        No\n",
              "9   France  37.0  67000.0       Yes"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3sECMZbkihC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:,3].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCu8dwV_rRA-",
        "colab_type": "code",
        "outputId": "709fc11a-3a4b-4c72-952a-32d358ec51a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, nan],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', nan, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBYFDskek5io",
        "colab_type": "code",
        "outputId": "01362177-85ac-45b4-db53-f7956af4683d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "X[:, 1:3]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[44.0, 72000.0],\n",
              "       [27.0, 48000.0],\n",
              "       [30.0, 54000.0],\n",
              "       [38.0, 61000.0],\n",
              "       [40.0, nan],\n",
              "       [35.0, 58000.0],\n",
              "       [nan, 52000.0],\n",
              "       [48.0, 79000.0],\n",
              "       [50.0, 83000.0],\n",
              "       [37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03FcWisvh-Px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imputer = imputer.fit(X[:, 1:3])\n",
        "#index in python start at 0, so we are going to take the second column and the third column. \n",
        "#We have to give +1 for the end column so that it takes it till 2."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThhdoF33jPla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
        "#transform is used to apply the changes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwj26xZtpDeI",
        "colab_type": "code",
        "outputId": "2217900e-a7e4-444c-9da1-b7c7cdc0f68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "X[:, 1:3]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[44.0, 72000.0],\n",
              "       [27.0, 48000.0],\n",
              "       [30.0, 54000.0],\n",
              "       [38.0, 61000.0],\n",
              "       [40.0, 63777.77777777778],\n",
              "       [35.0, 58000.0],\n",
              "       [38.77777777777778, 52000.0],\n",
              "       [48.0, 79000.0],\n",
              "       [50.0, 83000.0],\n",
              "       [37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neMZ790ypk4P",
        "colab_type": "text"
      },
      "source": [
        "##Categorical Data\n",
        "\n",
        "We would only want numbers in our dataset. Let's see how we can do that with categorical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3-1jknqpFx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# this is used for data transformation of categorical data\n",
        "labelEncoder_X = LabelEncoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j1PirBmrYxs",
        "colab_type": "code",
        "outputId": "c93d1a0f-1abd-42f8-c7f4-b78c587233dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, 63777.77777777778],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', 38.77777777777778, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_bOLLu3qp8I",
        "colab_type": "text"
      },
      "source": [
        "Let's encode the Countries column which is Spain, France and Germany and assign a number to each value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnelEfVqqiKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X[:, 0] =  labelEncoder_X.fit_transform(X[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqvjlYhGrIOk",
        "colab_type": "code",
        "outputId": "ff75f406-7ec0-4546-e8b1-6135d3689fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 44.0, 72000.0],\n",
              "       [2, 27.0, 48000.0],\n",
              "       [1, 30.0, 54000.0],\n",
              "       [2, 38.0, 61000.0],\n",
              "       [1, 40.0, 63777.77777777778],\n",
              "       [0, 35.0, 58000.0],\n",
              "       [2, 38.77777777777778, 52000.0],\n",
              "       [0, 48.0, 79000.0],\n",
              "       [1, 50.0, 83000.0],\n",
              "       [0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HizvPCjrcQl",
        "colab_type": "text"
      },
      "source": [
        "However, there is a problem with this. Since 1 is greater than 0 and 2 is greater than 1 and 2, the algorithm might tthink that Spain nis greater than France and Germany. So this is not exactly the right way. \n",
        "\n",
        "Id it would had been small, large and medium, it still could had made sense since large is greater than small and medium and so on. But here it does not make any sense. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq2G0amKsCR_",
        "colab_type": "text"
      },
      "source": [
        "## Dummy Encoding / One Hot Encoding\n",
        "\n",
        "Instead of having one column here, we are going to have 3(number of categories) columns representing the value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBonRkwfr9xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# this is used for data transformation of categorical data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78YBJ-czrJZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f2f40f8-1359-4ee2-9cf5-c7c251861682"
      },
      "source": [
        "help(OneHotEncoder())\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on OneHotEncoder in module sklearn.preprocessing._encoders object:\n",
            "\n",
            "class OneHotEncoder(_BaseEncoder)\n",
            " |  Encode categorical integer features as a one-hot numeric array.\n",
            " |  \n",
            " |  The input to this transformer should be an array-like of integers or\n",
            " |  strings, denoting the values taken on by categorical (discrete) features.\n",
            " |  The features are encoded using a one-hot (aka 'one-of-K' or 'dummy')\n",
            " |  encoding scheme. This creates a binary column for each category and\n",
            " |  returns a sparse matrix or dense array.\n",
            " |  \n",
            " |  By default, the encoder derives the categories based on the unique values\n",
            " |  in each feature. Alternatively, you can also specify the `categories`\n",
            " |  manually.\n",
            " |  The OneHotEncoder previously assumed that the input features take on\n",
            " |  values in the range [0, max(values)). This behaviour is deprecated.\n",
            " |  \n",
            " |  This encoding is needed for feeding categorical data to many scikit-learn\n",
            " |  estimators, notably linear models and SVMs with the standard kernels.\n",
            " |  \n",
            " |  Note: a one-hot encoding of y labels should use a LabelBinarizer\n",
            " |  instead.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  categories : 'auto' or a list of lists/arrays of values, default='auto'.\n",
            " |      Categories (unique values) per feature:\n",
            " |  \n",
            " |      - 'auto' : Determine categories automatically from the training data.\n",
            " |      - list : ``categories[i]`` holds the categories expected in the ith\n",
            " |        column. The passed categories should not mix strings and numeric\n",
            " |        values within a single feature, and should be sorted in case of\n",
            " |        numeric values.\n",
            " |  \n",
            " |      The used categories can be found in the ``categories_`` attribute.\n",
            " |  \n",
            " |  drop : 'first' or a list/array of shape (n_features,), default=None.\n",
            " |      Specifies a methodology to use to drop one of the categories per\n",
            " |      feature. This is useful in situations where perfectly collinear\n",
            " |      features cause problems, such as when feeding the resulting data\n",
            " |      into a neural network or an unregularized regression.\n",
            " |  \n",
            " |      - None : retain all features (the default).\n",
            " |      - 'first' : drop the first category in each feature. If only one\n",
            " |        category is present, the feature will be dropped entirely.\n",
            " |      - array : ``drop[i]`` is the category in feature ``X[:, i]`` that\n",
            " |        should be dropped.\n",
            " |  \n",
            " |  sparse : boolean, default=True\n",
            " |      Will return sparse matrix if set True else will return an array.\n",
            " |  \n",
            " |  dtype : number type, default=np.float\n",
            " |      Desired dtype of output.\n",
            " |  \n",
            " |  handle_unknown : 'error' or 'ignore', default='error'.\n",
            " |      Whether to raise an error or ignore if an unknown categorical feature\n",
            " |      is present during transform (default is to raise). When this parameter\n",
            " |      is set to 'ignore' and an unknown category is encountered during\n",
            " |      transform, the resulting one-hot encoded columns for this feature\n",
            " |      will be all zeros. In the inverse transform, an unknown category\n",
            " |      will be denoted as None.\n",
            " |  \n",
            " |  n_values : 'auto', int or array of ints, default='auto'\n",
            " |      Number of values per feature.\n",
            " |  \n",
            " |      - 'auto' : determine value range from training data.\n",
            " |      - int : number of categorical values per feature.\n",
            " |              Each feature value should be in ``range(n_values)``\n",
            " |      - array : ``n_values[i]`` is the number of categorical values in\n",
            " |                ``X[:, i]``. Each feature value should be\n",
            " |                in ``range(n_values[i])``\n",
            " |  \n",
            " |      .. deprecated:: 0.20\n",
            " |          The `n_values` keyword was deprecated in version 0.20 and will\n",
            " |          be removed in 0.22. Use `categories` instead.\n",
            " |  \n",
            " |  categorical_features : 'all' or array of indices or mask, default='all'\n",
            " |      Specify what features are treated as categorical.\n",
            " |  \n",
            " |      - 'all': All features are treated as categorical.\n",
            " |      - array of indices: Array of categorical feature indices.\n",
            " |      - mask: Array of length n_features and with dtype=bool.\n",
            " |  \n",
            " |      Non-categorical features are always stacked to the right of the matrix.\n",
            " |  \n",
            " |      .. deprecated:: 0.20\n",
            " |          The `categorical_features` keyword was deprecated in version\n",
            " |          0.20 and will be removed in 0.22.\n",
            " |          You can use the ``ColumnTransformer`` instead.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  categories_ : list of arrays\n",
            " |      The categories of each feature determined during fitting\n",
            " |      (in order of the features in X and corresponding with the output\n",
            " |      of ``transform``). This includes the category specified in ``drop``\n",
            " |      (if any).\n",
            " |  \n",
            " |  drop_idx_ : array of shape (n_features,)\n",
            " |      ``drop_idx_[i]`` isÂ the index in ``categories_[i]`` of the category to\n",
            " |      be dropped for each feature. None if all the transformed features will\n",
            " |      be retained.\n",
            " |  \n",
            " |  active_features_ : array\n",
            " |      Indices for active features, meaning values that actually occur\n",
            " |      in the training set. Only available when n_values is ``'auto'``.\n",
            " |  \n",
            " |      .. deprecated:: 0.20\n",
            " |          The ``active_features_`` attribute was deprecated in version\n",
            " |          0.20 and will be removed in 0.22.\n",
            " |  \n",
            " |  feature_indices_ : array of shape (n_features,)\n",
            " |      Indices to feature ranges.\n",
            " |      Feature ``i`` in the original data is mapped to features\n",
            " |      from ``feature_indices_[i]`` to ``feature_indices_[i+1]``\n",
            " |      (and then potentially masked by ``active_features_`` afterwards)\n",
            " |  \n",
            " |      .. deprecated:: 0.20\n",
            " |          The ``feature_indices_`` attribute was deprecated in version\n",
            " |          0.20 and will be removed in 0.22.\n",
            " |  \n",
            " |  n_values_ : array of shape (n_features,)\n",
            " |      Maximum number of values per feature.\n",
            " |  \n",
            " |      .. deprecated:: 0.20\n",
            " |          The ``n_values_`` attribute was deprecated in version\n",
            " |          0.20 and will be removed in 0.22.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  Given a dataset with two features, we let the encoder find the unique\n",
            " |  values per feature and transform the data to a binary one-hot encoding.\n",
            " |  \n",
            " |  >>> from sklearn.preprocessing import OneHotEncoder\n",
            " |  >>> enc = OneHotEncoder(handle_unknown='ignore')\n",
            " |  >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
            " |  >>> enc.fit(X)\n",
            " |  ... # doctest: +ELLIPSIS\n",
            " |  ... # doctest: +NORMALIZE_WHITESPACE\n",
            " |  OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
            " |     dtype=<... 'numpy.float64'>, handle_unknown='ignore',\n",
            " |     n_values=None, sparse=True)\n",
            " |  \n",
            " |  >>> enc.categories_\n",
            " |  [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
            " |  >>> enc.transform([['Female', 1], ['Male', 4]]).toarray()\n",
            " |  array([[1., 0., 1., 0., 0.],\n",
            " |         [0., 1., 0., 0., 0.]])\n",
            " |  >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n",
            " |  array([['Male', 1],\n",
            " |         [None, 2]], dtype=object)\n",
            " |  >>> enc.get_feature_names()\n",
            " |  array(['x0_Female', 'x0_Male', 'x1_1', 'x1_2', 'x1_3'], dtype=object)\n",
            " |  >>> drop_enc = OneHotEncoder(drop='first').fit(X)\n",
            " |  >>> drop_enc.categories_\n",
            " |  [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
            " |  >>> drop_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
            " |  array([[0., 0., 0.],\n",
            " |         [1., 1., 0.]])\n",
            " |  \n",
            " |  See also\n",
            " |  --------\n",
            " |  sklearn.preprocessing.OrdinalEncoder : performs an ordinal (integer)\n",
            " |    encoding of the categorical features.\n",
            " |  sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n",
            " |    dictionary items (also handles string-valued features).\n",
            " |  sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n",
            " |    encoding of dictionary items or strings.\n",
            " |  sklearn.preprocessing.LabelBinarizer : binarizes labels in a one-vs-all\n",
            " |    fashion.\n",
            " |  sklearn.preprocessing.MultiLabelBinarizer : transforms between iterable of\n",
            " |    iterables and a multilabel format, e.g. a (samples x classes) binary\n",
            " |    matrix indicating the presence of a class label.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      OneHotEncoder\n",
            " |      _BaseEncoder\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.base.TransformerMixin\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, n_values=None, categorical_features=None, categories=None, drop=None, sparse=True, dtype=<class 'numpy.float64'>, handle_unknown='error')\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y=None)\n",
            " |      Fit OneHotEncoder to X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape [n_samples, n_features]\n",
            " |          The data to determine the categories of each feature.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |  \n",
            " |  fit_transform(self, X, y=None)\n",
            " |      Fit OneHotEncoder to X, then transform X.\n",
            " |      \n",
            " |      Equivalent to fit(X).transform(X) but more convenient.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape [n_samples, n_features]\n",
            " |          The data to encode.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_out : sparse matrix if sparse=True else a 2-d array\n",
            " |          Transformed input.\n",
            " |  \n",
            " |  get_feature_names(self, input_features=None)\n",
            " |      Return feature names for output features.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      input_features : list of string, length n_features, optional\n",
            " |          String names for input features if available. By default,\n",
            " |          \"x0\", \"x1\", ... \"xn_features\" is used.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      output_feature_names : array of string, length n_output_features\n",
            " |  \n",
            " |  inverse_transform(self, X)\n",
            " |      Convert the back data to the original representation.\n",
            " |      \n",
            " |      In case unknown categories are encountered (all zeros in the\n",
            " |      one-hot encoding), ``None`` is used to represent this category.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like or sparse matrix, shape [n_samples, n_encoded_features]\n",
            " |          The transformed data.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_tr : array-like, shape [n_samples, n_features]\n",
            " |          Inverse transformed array.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Transform X using one-hot encoding.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape [n_samples, n_features]\n",
            " |          The data to encode.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_out : sparse matrix if sparse=True else a 2-d array\n",
            " |          Transformed input.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  active_features_\n",
            " |  \n",
            " |  feature_indices_\n",
            " |  \n",
            " |  n_values_\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : boolean, optional\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : mapping of string to any\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as pipelines). The latter have parameters of the form\n",
            " |      ``<component>__<parameter>`` so that it's possible to update each\n",
            " |      component of a nested object.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVSb5YHMdF3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onehotencoder = OneHotEncoder(categorical_features = [0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtAKtVL-wOpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#help(OneHotEncoder())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Az6q66Qso_T",
        "colab_type": "code",
        "outputId": "7f174f7b-955d-4b06-82d0-1f417e061828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "X = onehotencoder.fit_transform(X).toarray()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBhkzf0-dmea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "7a88003b-60c6-4629-f84a-7862ec964399"
      },
      "source": [
        "X"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.40000000e+01,\n",
              "        7.20000000e+04],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.70000000e+01,\n",
              "        4.80000000e+04],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.00000000e+01,\n",
              "        5.40000000e+04],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n",
              "        6.10000000e+04],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n",
              "        6.37777778e+04],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.50000000e+01,\n",
              "        5.80000000e+04],\n",
              "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.87777778e+01,\n",
              "        5.20000000e+04],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n",
              "        7.90000000e+04],\n",
              "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.00000000e+01,\n",
              "        8.30000000e+04],\n",
              "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n",
              "        6.70000000e+04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrMwt5Plurhf",
        "colab_type": "code",
        "outputId": "d161b617-a240-4b23-8831-4ec5467d449f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "pd.DataFrame(X)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>72000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>48000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>54000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>61000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>63777.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>58000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.777778</td>\n",
              "      <td>52000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>79000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>83000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>67000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2          3             4\n",
              "0  1.0  0.0  0.0  44.000000  72000.000000\n",
              "1  0.0  0.0  1.0  27.000000  48000.000000\n",
              "2  0.0  1.0  0.0  30.000000  54000.000000\n",
              "3  0.0  0.0  1.0  38.000000  61000.000000\n",
              "4  0.0  1.0  0.0  40.000000  63777.777778\n",
              "5  1.0  0.0  0.0  35.000000  58000.000000\n",
              "6  0.0  0.0  1.0  38.777778  52000.000000\n",
              "7  1.0  0.0  0.0  48.000000  79000.000000\n",
              "8  0.0  1.0  0.0  50.000000  83000.000000\n",
              "9  1.0  0.0  0.0  37.000000  67000.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJcTE3IR0cBz",
        "colab_type": "text"
      },
      "source": [
        "Let's take care of the Purchased column now. So we will be working with y.\n",
        "However, we do not need to use one hot encoder here, we can simplyt do this with labelEncoder as there are just two categories. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjXUXo0fvDtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelEncoder_y = LabelEncoder()\n",
        "y = labelEncoder_y.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4aw1OMA1Dcx",
        "colab_type": "code",
        "outputId": "22d47de6-02e8-4712-de84-a4de50397c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QToFExp3j7S",
        "colab_type": "text"
      },
      "source": [
        "Since the above code has depreciated, you can use the below code as well.\n",
        "\n",
        "Here, you do not need to use the labelEncoder and can directly work with the one hot encoder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZAsF_Pd1G-t",
        "colab_type": "code",
        "outputId": "d8b5da61-ad9a-4904-f70c-70639bd486e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "coltransf_X = ColumnTransformer([(\"one_hot_encoder\", OneHotEncoder(), [0])], remainder='passthrough')\n",
        "X = coltransf_X.fit_transform(X)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYqY3V0ggDuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05d11474-8c99-4640-89fb-5b095d7eb60d"
      },
      "source": [
        "help(ColumnTransformer)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class ColumnTransformer in module sklearn.compose._column_transformer:\n",
            "\n",
            "class ColumnTransformer(sklearn.utils.metaestimators._BaseComposition, sklearn.base.TransformerMixin)\n",
            " |  Applies transformers to columns of an array or pandas DataFrame.\n",
            " |  \n",
            " |  This estimator allows different columns or column subsets of the input\n",
            " |  to be transformed separately and the features generated by each transformer\n",
            " |  will be concatenated to form a single feature space.\n",
            " |  This is useful for heterogeneous or columnar data, to combine several\n",
            " |  feature extraction mechanisms or transformations into a single transformer.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <column_transformer>`.\n",
            " |  \n",
            " |  .. versionadded:: 0.20\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  transformers : list of tuples\n",
            " |      List of (name, transformer, column(s)) tuples specifying the\n",
            " |      transformer objects to be applied to subsets of the data.\n",
            " |  \n",
            " |      name : string\n",
            " |          Like in Pipeline and FeatureUnion, this allows the transformer and\n",
            " |          its parameters to be set using ``set_params`` and searched in grid\n",
            " |          search.\n",
            " |      transformer : estimator or {'passthrough', 'drop'}\n",
            " |          Estimator must support `fit` and `transform`. Special-cased\n",
            " |          strings 'drop' and 'passthrough' are accepted as well, to\n",
            " |          indicate to drop the columns or to pass them through untransformed,\n",
            " |          respectively.\n",
            " |      column(s) : string or int, array-like of string or int, slice, boolean mask array or callable\n",
            " |          Indexes the data on its second axis. Integers are interpreted as\n",
            " |          positional columns, while strings can reference DataFrame columns\n",
            " |          by name.  A scalar string or int should be used where\n",
            " |          ``transformer`` expects X to be a 1d array-like (vector),\n",
            " |          otherwise a 2d array will be passed to the transformer.\n",
            " |          A callable is passed the input data `X` and can return any of the\n",
            " |          above.\n",
            " |  \n",
            " |  remainder : {'drop', 'passthrough'} or estimator, default 'drop'\n",
            " |      By default, only the specified columns in `transformers` are\n",
            " |      transformed and combined in the output, and the non-specified\n",
            " |      columns are dropped. (default of ``'drop'``).\n",
            " |      By specifying ``remainder='passthrough'``, all remaining columns that\n",
            " |      were not specified in `transformers` will be automatically passed\n",
            " |      through. This subset of columns is concatenated with the output of\n",
            " |      the transformers.\n",
            " |      By setting ``remainder`` to be an estimator, the remaining\n",
            " |      non-specified columns will use the ``remainder`` estimator. The\n",
            " |      estimator must support :term:`fit` and :term:`transform`.\n",
            " |  \n",
            " |  sparse_threshold : float, default = 0.3\n",
            " |      If the output of the different transformers contains sparse matrices,\n",
            " |      these will be stacked as a sparse matrix if the overall density is\n",
            " |      lower than this value. Use ``sparse_threshold=0`` to always return\n",
            " |      dense.  When the transformed output consists of all dense data, the\n",
            " |      stacked result will be dense, and this keyword will be ignored.\n",
            " |  \n",
            " |  n_jobs : int or None, optional (default=None)\n",
            " |      Number of jobs to run in parallel.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |  \n",
            " |  transformer_weights : dict, optional\n",
            " |      Multiplicative weights for features per transformer. The output of the\n",
            " |      transformer is multiplied by these weights. Keys are transformer names,\n",
            " |      values the weights.\n",
            " |  \n",
            " |  verbose : boolean, optional(default=False)\n",
            " |      If True, the time elapsed while fitting each transformer will be\n",
            " |      printed as it is completed.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  transformers_ : list\n",
            " |      The collection of fitted transformers as tuples of\n",
            " |      (name, fitted_transformer, column). `fitted_transformer` can be an\n",
            " |      estimator, 'drop', or 'passthrough'. In case there were no columns\n",
            " |      selected, this will be the unfitted transformer.\n",
            " |      If there are remaining columns, the final element is a tuple of the\n",
            " |      form:\n",
            " |      ('remainder', transformer, remaining_columns) corresponding to the\n",
            " |      ``remainder`` parameter. If there are remaining columns, then\n",
            " |      ``len(transformers_)==len(transformers)+1``, otherwise\n",
            " |      ``len(transformers_)==len(transformers)``.\n",
            " |  \n",
            " |  named_transformers_ : Bunch object, a dictionary with attribute access\n",
            " |      Read-only attribute to access any transformer by given name.\n",
            " |      Keys are transformer names and values are the fitted transformer\n",
            " |      objects.\n",
            " |  \n",
            " |  sparse_output_ : boolean\n",
            " |      Boolean flag indicating wether the output of ``transform`` is a\n",
            " |      sparse matrix or a dense numpy array, which depends on the output\n",
            " |      of the individual transformers and the `sparse_threshold` keyword.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The order of the columns in the transformed feature matrix follows the\n",
            " |  order of how the columns are specified in the `transformers` list.\n",
            " |  Columns of the original feature matrix that are not specified are\n",
            " |  dropped from the resulting transformed feature matrix, unless specified\n",
            " |  in the `passthrough` keyword. Those columns specified with `passthrough`\n",
            " |  are added at the right to the output of the transformers.\n",
            " |  \n",
            " |  See also\n",
            " |  --------\n",
            " |  sklearn.compose.make_column_transformer : convenience function for\n",
            " |      combining the outputs of multiple transformer objects applied to\n",
            " |      column subsets of the original feature space.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> import numpy as np\n",
            " |  >>> from sklearn.compose import ColumnTransformer\n",
            " |  >>> from sklearn.preprocessing import Normalizer\n",
            " |  >>> ct = ColumnTransformer(\n",
            " |  ...     [(\"norm1\", Normalizer(norm='l1'), [0, 1]),\n",
            " |  ...      (\"norm2\", Normalizer(norm='l1'), slice(2, 4))])\n",
            " |  >>> X = np.array([[0., 1., 2., 2.],\n",
            " |  ...               [1., 1., 0., 1.]])\n",
            " |  >>> # Normalizer scales each row of X to unit norm. A separate scaling\n",
            " |  >>> # is applied for the two first and two last elements of each\n",
            " |  >>> # row independently.\n",
            " |  >>> ct.fit_transform(X)    # doctest: +NORMALIZE_WHITESPACE\n",
            " |  array([[0. , 1. , 0.5, 0.5],\n",
            " |         [0.5, 0.5, 0. , 1. ]])\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      ColumnTransformer\n",
            " |      sklearn.utils.metaestimators._BaseComposition\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.base.TransformerMixin\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, transformers, remainder='drop', sparse_threshold=0.3, n_jobs=None, transformer_weights=None, verbose=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y=None)\n",
            " |      Fit all transformers using X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like or DataFrame of shape [n_samples, n_features]\n",
            " |          Input data, of which specified subsets are used to fit the\n",
            " |          transformers.\n",
            " |      \n",
            " |      y : array-like, shape (n_samples, ...), optional\n",
            " |          Targets for supervised learning.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : ColumnTransformer\n",
            " |          This estimator\n",
            " |  \n",
            " |  fit_transform(self, X, y=None)\n",
            " |      Fit all transformers, transform the data and concatenate results.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like or DataFrame of shape [n_samples, n_features]\n",
            " |          Input data, of which specified subsets are used to fit the\n",
            " |          transformers.\n",
            " |      \n",
            " |      y : array-like, shape (n_samples, ...), optional\n",
            " |          Targets for supervised learning.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_t : array-like or sparse matrix, shape (n_samples, sum_n_components)\n",
            " |          hstack of results of transformers. sum_n_components is the\n",
            " |          sum of n_components (output dimension) over transformers. If\n",
            " |          any result is a sparse matrix, everything will be converted to\n",
            " |          sparse matrices.\n",
            " |  \n",
            " |  get_feature_names(self)\n",
            " |      Get feature names from all transformers.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_names : list of strings\n",
            " |          Names of the features produced by transform.\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : boolean, optional\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : mapping of string to any\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **kwargs)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      Valid parameter keys can be listed with ``get_params()``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Transform X separately by each transformer, concatenate results.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like or DataFrame of shape [n_samples, n_features]\n",
            " |          The data to be transformed by subset.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_t : array-like or sparse matrix, shape (n_samples, sum_n_components)\n",
            " |          hstack of results of transformers. sum_n_components is the\n",
            " |          sum of n_components (output dimension) over transformers. If\n",
            " |          any result is a sparse matrix, everything will be converted to\n",
            " |          sparse matrices.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  named_transformers_\n",
            " |      Access the fitted transformer by name.\n",
            " |      \n",
            " |      Read-only attribute to access any transformer by given name.\n",
            " |      Keys are transformer names and values are the fitted transformer\n",
            " |      objects.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRCSX9KA3bzF",
        "colab_type": "code",
        "outputId": "0541bbe9-2353-41fe-f29c-358af2e3a08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "pd.DataFrame(X)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>72000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>48000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>54000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>61000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>63777.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>58000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.777778</td>\n",
              "      <td>52000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>79000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>83000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>67000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3          4             5\n",
              "0  0.0  1.0  0.0  0.0  44.000000  72000.000000\n",
              "1  1.0  0.0  0.0  1.0  27.000000  48000.000000\n",
              "2  1.0  0.0  1.0  0.0  30.000000  54000.000000\n",
              "3  1.0  0.0  0.0  1.0  38.000000  61000.000000\n",
              "4  1.0  0.0  1.0  0.0  40.000000  63777.777778\n",
              "5  0.0  1.0  0.0  0.0  35.000000  58000.000000\n",
              "6  1.0  0.0  0.0  1.0  38.777778  52000.000000\n",
              "7  0.0  1.0  0.0  0.0  48.000000  79000.000000\n",
              "8  1.0  0.0  1.0  0.0  50.000000  83000.000000\n",
              "9  0.0  1.0  0.0  0.0  37.000000  67000.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OZmquQI4cfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?ColumnTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ0e_1CWhtST",
        "colab_type": "text"
      },
      "source": [
        "##Data Splitting\n",
        "\n",
        "Split data into test and training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DjU5gd5gjJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the data into training and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jxWXNCahz_l",
        "colab_type": "text"
      },
      "source": [
        "##Feature Scaling\n",
        "\n",
        "Convert the data into the same scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oy_FrTQ3ckq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU70futY5m2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "# we have already fit the data with the train set so we do not need to fit it again\n",
        "#so only transform is run on the test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIjq9gD038cr",
        "colab_type": "code",
        "outputId": "90ae8031-1819-4d56-c484-d67d00c762bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "pd.DataFrame(X_train)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.645751</td>\n",
              "      <td>-0.774597</td>\n",
              "      <td>0.263068</td>\n",
              "      <td>0.123815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.377964</td>\n",
              "      <td>-0.774597</td>\n",
              "      <td>-0.253501</td>\n",
              "      <td>0.461756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.377964</td>\n",
              "      <td>1.290994</td>\n",
              "      <td>-1.975398</td>\n",
              "      <td>-1.530933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.377964</td>\n",
              "      <td>1.290994</td>\n",
              "      <td>0.052614</td>\n",
              "      <td>-1.111420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.377964</td>\n",
              "      <td>-0.774597</td>\n",
              "      <td>1.640585</td>\n",
              "      <td>1.720297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.377964</td>\n",
              "      <td>1.290994</td>\n",
              "      <td>-0.081312</td>\n",
              "      <td>-0.167514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.377964</td>\n",
              "      <td>-0.774597</td>\n",
              "      <td>0.951826</td>\n",
              "      <td>0.986148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.377964</td>\n",
              "      <td>-0.774597</td>\n",
              "      <td>-0.597881</td>\n",
              "      <td>-0.482149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1         2         3         4         5\n",
              "0  1.0 -1.0  2.645751 -0.774597  0.263068  0.123815\n",
              "1 -1.0  1.0 -0.377964 -0.774597 -0.253501  0.461756\n",
              "2  1.0 -1.0 -0.377964  1.290994 -1.975398 -1.530933\n",
              "3  1.0 -1.0 -0.377964  1.290994  0.052614 -1.111420\n",
              "4 -1.0  1.0 -0.377964 -0.774597  1.640585  1.720297\n",
              "5  1.0 -1.0 -0.377964  1.290994 -0.081312 -0.167514\n",
              "6 -1.0  1.0 -0.377964 -0.774597  0.951826  0.986148\n",
              "7 -1.0  1.0 -0.377964 -0.774597 -0.597881 -0.482149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz7nZX3zhhpz",
        "colab_type": "code",
        "outputId": "9be1c837-9927-491c-9c23-305009c632a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "pd.DataFrame(X_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.645751</td>\n",
              "      <td>-0.774597</td>\n",
              "      <td>-1.458829</td>\n",
              "      <td>-0.901663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.645751</td>\n",
              "      <td>-0.774597</td>\n",
              "      <td>1.984964</td>\n",
              "      <td>2.139811</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1         2         3         4         5\n",
              "0  1.0 -1.0  2.645751 -0.774597 -1.458829 -0.901663\n",
              "1  1.0 -1.0  2.645751 -0.774597  1.984964  2.139811"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oThgzoe3hlIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we do not need to transform the"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htsXQ0n6dgkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}